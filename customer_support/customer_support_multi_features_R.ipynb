{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b6a728-2b33-4b0a-97a1-195cdfe8616b",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58bf5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset #, load_metric\n",
    "from peft import LoraConfig, get_peft_model, AutoPeftModelForCausalLM\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math\n",
    "import sacrebleu "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17126374-abed-4c4c-b106-ffd1f67266eb",
   "metadata": {},
   "source": [
    "### Check cuda available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bb06ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available: True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "check_cuda = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device('cuda' if check_cuda else 'cpu')\n",
    "print(f\"Cuda is available: {'True' if check_cuda else 'False'}\\nUsing device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f368e992-8b13-4de1-87ed-9649aac8c908",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5c34d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('bitext/Bitext-customer-support-llm-chatbot-training-dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69895e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['flags', 'instruction', 'category', 'intent', 'response'],\n",
      "        num_rows: 26872\n",
      "    })\n",
      "})\n",
      "dict_keys(['train'])\n",
      "\n",
      "intent: \n",
      "{'cancel_order', 'create_account', 'change_shipping_address', 'recover_password', 'review', 'check_cancellation_fee', 'contact_human_agent', 'change_order', 'check_payment_methods', 'payment_issue', 'track_refund', 'switch_account', 'complaint', 'get_refund', 'edit_account', 'set_up_shipping_address', 'delivery_period', 'check_refund_policy', 'contact_customer_service', 'delivery_options', 'delete_account', 'newsletter_subscription', 'registration_problems', 'get_invoice', 'track_order', 'place_order', 'check_invoice'}\n",
      "\n",
      "category: \n",
      "{'ORDER', 'CONTACT', 'REFUND', 'FEEDBACK', 'CANCEL', 'SHIPPING', 'INVOICE', 'DELIVERY', 'SUBSCRIPTION', 'PAYMENT', 'ACCOUNT'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset.keys())\n",
    "# print(f\"\\nflags: \\n{set(dataset['train']['flags'])}\")\n",
    "# print(f\"\\ninstruction: \\n{set(dataset['train']['instruction'])}\")\n",
    "print(f\"\\nintent: \\n{set(dataset['train']['intent'])}\")\n",
    "print(f\"\\ncategory: \\n{set(dataset['train']['category'])}\")\n",
    "# print(f\"\\nresponse: \\n{set(dataset['train']['response'])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d0e51",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> This dataset only contains a **train** split.\n",
    "> Need to manually aplit it into training, validation, and test sets for model evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa96f4a0-f97d-4f0d-b23b-63770450e8de",
   "metadata": {},
   "source": [
    "# Load the Tokenizer and Model\n",
    "### Model Selection\n",
    "Microsoft `DialogGTP-medium` is available in [huggingface](https://huggingface.co/microsoft/DialoGPT-medium) which fine-tuned on Reddit conversation data. \n",
    "- Model Size and Resource Balance: The `DialoGPT-medium model` provides a good balance between size and resource usage, making it suitable for handling conversational tasks efficiently without overloading system resources.\n",
    "- Pre-trained Knowledge Base: Since it is pre-trained on a vast set of Reddit conversations, it’s equipped with a wide-ranging understanding of language patterns. This helps to interpret and generate coherent responses across diverse conversational topics.\n",
    "- Optimized for Dialogue: Built specifically for conversation, DialoGPT-medium naturally excels at creating engaging responses. Its training makes it well-suited to jump into dialogue, making it a great choice for applications centered around conversation.\n",
    "\n",
    "\n",
    "> [!NOTE]\n",
    "> **pad_token**: This token is used to fill in extra space so that all sequences in a batch are the same length, making batch processing smoother and more efficient.\n",
    "> **eos_token**: Short for \"End of Sequence,\" this token marks where a sequence finishes, signaling to the model that it’s reached the end of the input or output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2fa9a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding token\n",
      "Pad token: <|endoftext|>, ID: 50256\n",
      "EOS token: <|endoftext|>, ID: 50256\n",
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 1024)\n",
      "    (wpe): Embedding(1024, 1024)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-23): 24 x GPT2Block(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2SdpaAttention(\n",
      "          (c_attn): Conv1D(nf=3072, nx=1024)\n",
      "          (c_proj): Conv1D(nf=1024, nx=1024)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=4096, nx=1024)\n",
      "          (c_proj): Conv1D(nf=1024, nx=4096)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load the Tokenizer and Model from Hugging Face\n",
    "model_name = 'microsoft/DialoGPT-medium'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set the pad_token to eos_token: \n",
    "# This helps avoid unwanted attention on padded positions because, during training, \n",
    "# the model learned to ignore anything after the eos_token.\n",
    "if tokenizer.pad_token is None:\n",
    "    print(\"Padding token\")\n",
    "    # tokenizer.add_special_tokens({'pad_token': '[PAD]'}) # For fine-tuning the model on tasks requiring distinct padding\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Verify the pad_token:\n",
    "# Padding is handled correctly to prevent unintended behavior during training and inference\n",
    "print(f\"Pad token: {tokenizer.pad_token}, ID: {tokenizer.pad_token_id}\")\n",
    "print(f\"EOS token: {tokenizer.eos_token}, ID: {tokenizer.eos_token_id}\")\n",
    "\n",
    "# NOTE!\n",
    "# Shows that both pad_token and eos_token are set correctly and have the same ID 50256\n",
    "# If mismatch the assigned token, padding may not work correcly. It could lead issues in downstream tasks like training convergence or inference accuracy\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Resize the embeddings to accommodate the new pad_token\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# move model to cuda in my case\n",
    "model.to(device)\n",
    "\n",
    "# Check the model architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4977024f-92c7-4344-a7f5-d1904f3a27af",
   "metadata": {},
   "source": [
    ">[!NOTE]\n",
    "> In GPT2LMHeadModel, c_attn and c_proj handle attention related transformations.\n",
    "> It allows the model to learn new patterns in the attention mechanism to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde1888a-8465-4ade-8dfb-7bf9637524af",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Applied this function to format the conversation correctly. This function apply user instructions and assistnat response with proper tokenization. Each conversation is formatted w/ User and Assistant, separated by 'eos_token'.\n",
    "\n",
    "Features are used: `instruction`, `response`, `category`, `intent`\n",
    "\n",
    "Added multiple context to the model which can enhance its ability to generate accurate and relevant response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a33a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    conversations = []\n",
    "    # Features used: `instruction`, `response`, `category`, `intent`\n",
    "    for instruction, response, category, intent in zip(examples['instruction'], examples['response'], examples['category'], examples['intent']):\n",
    "        conversation = (\n",
    "                        f\"{tokenizer.eos_token}Category: {category}{tokenizer.eos_token}\"\n",
    "                        f\"Intent: {intent}{tokenizer.eos_token}\"\n",
    "                        f\"User(Customer): {instruction}{tokenizer.eos_token} \"\n",
    "                        f\"Service Assistant: {response}{tokenizer.eos_token}\"\n",
    "                        # f\"<BOS> Category: {category} </BOS>\"\n",
    "                        # f\"<BOS> Intent: {intent} </BOS>\"\n",
    "                        # f\"<BOS> User: {instruction} </BOS>\"\n",
    "                        # f\"<BOS> Assistant: {response} </BOS>\"\n",
    "                        )\n",
    "        conversations.append(conversation)\n",
    "\n",
    "    # The tokenizer converts the conversations into input IDs, padding/truncating them to a maximum length of 512 tokens\n",
    "    model_inputs = tokenizer(conversations, max_length=512, truncation=True, padding='max_length')\n",
    "    \n",
    "    # The model is trained to predict the next token in the sequence, so labels are set as a copy of the input IDs.\n",
    "    model_inputs['labels'] = model_inputs['input_ids'].copy()\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7cb833-4e79-4710-adcb-8bcf989da625",
   "metadata": {},
   "source": [
    "# Tokenize and Split the Dataset\n",
    "- Applied 10% of the data for evaluation\n",
    "- For efficiency, set to batched=True, which the preprocess_function receives a batch of examples at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c469770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize & Split the Dataset\n",
    "tokenized_dataset = dataset['train'].map(preprocess_function, batched=True, remove_columns=dataset['train'].column_names)\n",
    "\n",
    "# Split the dataset into train and eval sets\n",
    "split_datasets = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = split_datasets['train']\n",
    "eval_dataset = split_datasets['test']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c09edbc-3bc0-4ede-b136-efd87e8a695a",
   "metadata": {},
   "source": [
    "# Create PEFT (LoRA) Configuration\n",
    "- r (Rank): Determines the size of the low-rank matrices. A smaller r means fewer parameters.\n",
    "- lora_alpha: Scaling factor to balance the contribution of the LoRA layers.\n",
    "- target_modules: Specifies which layers in the model to apply LoRA. For DialoGPT (based on GPT-2), \"c_attn\" and \"c_proj\" are common targets (Check model archetecture above)\n",
    "- lora_dropout: Dropout rate applied to the LoRA layers.\n",
    "- bias: How biases are handled. Setted to \"none\" which the model’s biases remain untouched during training. \n",
    "- task_type: Defines the task type. For causal language modeling, use \"CAUSAL_LM\" (Task type: Causal Language Modeling).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b75889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEFT Config\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fbcc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2f98d1c-2c86-4d1f-89a4-3c515dea56a2",
   "metadata": {},
   "source": [
    "# Convert to PEFT Model and Check Trainable Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3126fe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r0b0t4rl/anaconda3/envs/genAI/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1150: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,162,688 || all params: 356,985,856 || trainable%: 0.6058\n"
     ]
    }
   ],
   "source": [
    "# Convert to PEFT Model: Integrate the LoRA adapters into the pre-trained model using the configuration defined above.\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "\n",
    "peft_model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af40a342-0728-4e87-ae82-ee10ce29f7a4",
   "metadata": {},
   "source": [
    "Only 0.6058% of the total model parameters are trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c94e739-2296-413c-b8cf-cb17a4edec80",
   "metadata": {},
   "source": [
    "# Training Arguments\n",
    "[Training Arguments](https://huggingface.co/docs/transformers/en/main_classes/trainer)\n",
    "- output_dir: Directory to save model checkpoints\n",
    "\n",
    "Defines the number of samples processed per device (GPU/CPU) during training and evaluation.\n",
    "- per_device_train_batch_size: Batch size per device during training\n",
    "- per_device_eval_batch_size: Batch size per device during evaluation\n",
    "\n",
    "> [!TIP]\n",
    "> Large Batch Size: It will lead faster training per epoch but require more epochs to converge.\n",
    "> Smaller Batch Size: Take more time per epoch.\n",
    "> Adjust Batch size based on GPU memory (nvidia-smi)\n",
    "> In my case used smaller batch sizes with gradient accumulation\n",
    "gradient_accumulation_steps=4,  # Number of update steps to accumulate before performing a backward/update pass\n",
    "\n",
    "- num_train_epochs: Total number of training epochs. It specify the # of times the training algorithm will work through the entrie training dataset.\n",
    "\n",
    "> [!TIP]\n",
    "> For dataset size, smaller datasets may require more epochs to generalize well.\n",
    "> Overfitting risk can be consider if too many epochs. Make sure monitor validation loss to determine when to stop.\n",
    "> More epochs will take longer training times.\n",
    "\n",
    "- learning_rate: Learning rate determines the step size at each iter while moving toward a min of loss func.\n",
    "- fp16: Enable mixed precision training if GPU is available. It enables mixed precision training, which uses 16-bit floating point numers to reduce memory usage and speed up training.\n",
    "\n",
    "- logging_steps: Log training metrics every 100 steps which determines how often in step training metrics are logged.\n",
    "\n",
    "- eval_strategy: Evaluation strategy ('steps', 'epoch', 'no') specify when to run evaluation during training. Choosed 'step' in order to evaluate the model at regular intervals.\n",
    "- eval_steps: Evaluate every # of steps.\n",
    "\n",
    "- save_strategy: Save strategy for model checkpoints\n",
    "- save_steps: Save checkpoint at # of steps\n",
    "\n",
    "- report_to: Integrations for logging ('tensorboard', 'wandb', 'comet_ml'). 'None': Disable reporting to external services.\n",
    "\n",
    "- load_best_model_at_end: Load the best model at the end of training\n",
    "- metric_for_best_model: Metric to use to evaluate the best model. Commonly used loss.\n",
    "- greater_is_better: For loss, lower is better. This indicates whether a higher metric value is better.\n",
    "- logging_dir: Directory for storing logs for monitoring training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "901cd353",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./customer_support_chatbot_peft2',\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,  # Reduced epochs to prevent overfitting\n",
    "    learning_rate=3e-5,  # Slightly lower learning rate for better convergence\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=500, \n",
    "    save_strategy='steps',\n",
    "    save_steps=500,\n",
    "    report_to='none',\n",
    "    save_total_limit=2,  # Limit the total number of saved checkpoints\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_loss',\n",
    "    greater_is_better=False,\n",
    "    logging_dir='./logs',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f16075-569a-406c-a7ec-4ca2f1057773",
   "metadata": {},
   "source": [
    "## Evaluate the Pre-Trained Model \n",
    "- Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bdebcc5b-b0bf-46fc-a596-8f716f8fac5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='672' max='672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [672/672 00:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrained Model Perplexity: 1901.6922739434885\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Trainer for the pre-trained (Foundation) Model\n",
    "foundation_trainer = Trainer(\n",
    "    model=foundation_model,\n",
    "    args=training_args,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Evaluate the Foundation Model\n",
    "eval_results_foundation = foundation_trainer.evaluate()\n",
    "perplexity_foundation = math.exp(eval_results_foundation['eval_loss'])\n",
    "print(f\"PreTrained Model Perplexity: {perplexity_foundation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca293d5-b79f-42c1-9b7d-28b17885f2a5",
   "metadata": {},
   "source": [
    "# Create Data Collator\n",
    "Define a [data collator](https://huggingface.co/docs/transformers/en/main_classes/data_collator) that will dynamically pad the inputs during training. A data collator is a function that is responsible for batch formation during training and evaluation. It processes individual dataset examples and combines them into a batch, applying necessary transformations such as padding and masking.\n",
    "\n",
    "Specifically designed for language modeling tasks, this data collator handles the creation of batches for training language models.\n",
    "- tokenizer: The tokenizer used to process the text data (It is necessary for padding and creating attention masks)\n",
    "- mlm:Masked Language Modeling(mlm)\n",
    "> [!TIP]\n",
    "> mlm=True\n",
    "> Used in models like BERT, where some tokens are masked, and the model is trained to predict them.\n",
    ">\n",
    "> mlm=False\n",
    "> The model is trained to predict the next token in the sequence.\n",
    ">\n",
    "> mlm is not appropriate for causal language models like GPT-2 or DialoGPT. False setting aligns with the training objectives of causal language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87b638db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)  # Masked Language Modeling is disabled for causal language models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281faafe-727f-4df4-b0ef-2ed4e60ca5cd",
   "metadata": {},
   "source": [
    "# Initialize the Trainer\n",
    "Set up the Hugging Face Trainer with the PEFT model, training arguments, datasets, and data collator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ece7aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e7d00d-d227-40ca-bb50-095199b98b32",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d302b4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4533' max='4533' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4533/4533 54:26, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.603700</td>\n",
       "      <td>2.259510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.055900</td>\n",
       "      <td>1.822832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.857600</td>\n",
       "      <td>1.647718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.728300</td>\n",
       "      <td>1.539233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.665900</td>\n",
       "      <td>1.460746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.600700</td>\n",
       "      <td>1.398751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.575300</td>\n",
       "      <td>1.367623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.533000</td>\n",
       "      <td>1.352919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.526900</td>\n",
       "      <td>1.346978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4533, training_loss=1.9689473165414888, metrics={'train_runtime': 3267.0057, 'train_samples_per_second': 22.207, 'train_steps_per_second': 1.388, 'total_flos': 6.783866386985779e+16, 'train_loss': 1.9689473165414888, 'epoch': 2.9990076083360897})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787706ac-26a6-485d-acd5-3a624f5e98df",
   "metadata": {},
   "source": [
    "## Evaluate the PEFT Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf91f17e-2e72-4b79-9f2d-84d8f890b97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained Model Perplexity: 1901.6922739434885\n",
      "PEFT Model Perplexity: 3.845786708271636\n"
     ]
    }
   ],
   "source": [
    "# PEFT fine-tuned model\n",
    "eval_results_peft = trainer.evaluate()\n",
    "perplexity_peft = math.exp(eval_results_peft['eval_loss'])\n",
    "print(f\"Pre-trained Model Perplexity: {perplexity_foundation}\")\n",
    "print(f\"PEFT Model Perplexity: {perplexity_peft}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31051b73-476a-40d3-afd0-19ab39e10047",
   "metadata": {},
   "source": [
    "[**Perplexity**](https://huggingface.co/docs/transformers/en/perplexity) measures how well a probability model predicts a sample. In the context of language models, compare to orifinal foundation model, PEFT model has lower perplexity which indicates better performance. The PEFT model is more confident and accurate in predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150b7768-d87c-4852-a306-9a5bdf4415aa",
   "metadata": {},
   "source": [
    "## Compute BLEU Score for PEFT Model\n",
    "generate_response_peft:\n",
    "- model: The pre-trained language model.\n",
    "- tokenizer: Tokenizer associated with the model for encoding and decoding text.\n",
    "- instruction: The user input(prompt) to which the model should respond.\n",
    "- category (optional): 'unknown'\n",
    "- intent (optional): 'unknown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f568c6db-8d2f-4d06-ade3-db2f1e9ef989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT Model SacreBLEU Score: 3.9768704821496477\n"
     ]
    }
   ],
   "source": [
    "# Compute BLEU Score for the PEFT Model using SacreBLEU\n",
    "from sacrebleu.metrics import BLEU\n",
    "\n",
    "\n",
    "# def generate_response_peft(model, tokenizer, instruction, category='unknown', intent='unknown'):\n",
    "#     # Use eos_token as delimiters in the conversation format\n",
    "#     conversation = (\n",
    "#         f\"<BOS> Category: {category} </BOS>\"\n",
    "#         f\"<BOS> Intent: {intent} </BOS>\"\n",
    "#         f\"<BOS> User: {instruction} </BOS>\"\n",
    "#         f\"<BOS> Assistant:\"\n",
    "#     )\n",
    "#     inputs = tokenizer(conversation, return_tensors='pt', padding=True).to(device) # Tokenize the conversation\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model.generate(\n",
    "#             input_ids=inputs[\"input_ids\"],\n",
    "#             attention_mask=inputs[\"attention_mask\"],\n",
    "#             max_new_tokens=50,\n",
    "#             pad_token_id=tokenizer.pad_token_id,\n",
    "#             eos_token_id=tokenizer.eos_token_id,\n",
    "#             top_p=0.9,\n",
    "#             temperature=0.7,\n",
    "#             do_sample=True,\n",
    "#         )\n",
    "#     response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "#     assistant_reply = response.split('<BOS> Assistant:')[-1].strip()\n",
    "#     return assistant_reply\n",
    "\n",
    "def generate_response_peft(model, tokenizer, instruction, category='unknown', intent='unknown'):\n",
    "    # Use eos_token as delimiters in the conversation format\n",
    "    conversation = (\n",
    "        f\"{tokenizer.eos_token}Category: {category}{tokenizer.eos_token}\"\n",
    "        f\"Intent: {intent}{tokenizer.eos_token}\"\n",
    "        f\"User: {instruction}{tokenizer.eos_token}\"\n",
    "        f\"Assistant:\"\n",
    "    )\n",
    "    inputs = tokenizer(conversation, return_tensors='pt', padding=True).to(device) # Tokenize the conversation\n",
    "    \n",
    "    # Generate the response from the model w/out computing gradients\n",
    "    with torch.no_grad():\n",
    "        # Invokes the model's txt generation cability\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_new_tokens=50, # Limit the response to 50 new tokens to avoid long outputs\n",
    "            pad_token_id=tokenizer.pad_token_id,  # Padding handling. TokenID used for padding sequence.\n",
    "            eos_token_id=tokenizer.eos_token_id,  # Set model stops generation at eos_token\n",
    "            top_p=0.9,  # Nucleus sampling for diverse outputs. Promotes diversirty in the generated responses\n",
    "            temperature=0.7, # Control the randomness of predictions by scaling the logits before applying softmax.\n",
    "            do_sample=True,  # non-deterministic\n",
    "        )\n",
    "    \n",
    "    # Decode the output and extract the assistant's reply. Convert the generated IDs back into human-readable string.\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    assistant_reply = response.split(f\"Assistant:\")[-1].strip()  # Extract response after 'Assistant:'\n",
    "    return assistant_reply\n",
    "\n",
    "\n",
    "# Computes the BLEU score btween the model's generated responses and the reference responses in the dataset.\n",
    "def compute_bleu_sacrebleu(model, tokenizer, dataset):\n",
    "    references = []\n",
    "    predictions = []\n",
    "\n",
    "    # BLEU score compute\n",
    "    for example in dataset:\n",
    "        input_ids = example['input_ids']\n",
    "        labels = example['labels']\n",
    "        \n",
    "        # Decode the conversation\n",
    "        conversation_text = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "        instruction_text = conversation_text.split('User:')[-1].split('Assistant:')[0].strip()\n",
    "        \n",
    "        # Decode the reference response\n",
    "        label_text = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "        reference_response = label_text.split('Assistant:')[-1].strip()\n",
    "        \n",
    "        # Generate the model's response\n",
    "        generated_response = generate_response_peft(model, tokenizer, instruction_text)\n",
    "        \n",
    "        # Collect reference and generated rsponse\n",
    "        references.append(reference_response)\n",
    "        predictions.append(generated_response)\n",
    "    \n",
    "    # Compute BLEU score using SacreBLEU\n",
    "    bleu = BLEU()\n",
    "    score = bleu.corpus_score(predictions, [references]) # Compute the BLEU score over the entire corpus (predictions and references)\n",
    "    return score.score\n",
    "\n",
    "# Calculate BLEU Score\n",
    "bleu_score_peft = compute_bleu_sacrebleu(peft_model, tokenizer, eval_dataset)\n",
    "print(f\"PEFT Model SacreBLEU Score: {bleu_score_peft}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d064874-a1f0-4bd7-b206-2d71ea485019",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> **Higher BLEU Score:** Indicates closer similarity between the generated text and the reference text.\n",
    "> **Lower BLEU Score:** Suggests greater divergence from the reference.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353ee12e-80c0-41bf-b6fd-2d2f6d928c84",
   "metadata": {},
   "source": [
    "# Compare Original and PEFT Model\n",
    "\n",
    "## Load the Original Foundation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3272f272-e71e-4964-be93-156be8c147d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1024)\n",
       "    (wpe): Embedding(1024, 1024)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "          (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "          (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Original Foundation Model\n",
    "foundation_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "foundation_model.resize_token_embeddings(len(tokenizer))  # Ensure embeddings match tokenizer\n",
    "foundation_model.to(device)\n",
    "foundation_model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6230c1de-2cd9-45fd-8581-4767cf32111a",
   "metadata": {},
   "source": [
    "## Evaluate the Original Foundation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f3f5fd1e-1c4e-4698-8f03-7478440b0801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='672' max='672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [672/672 00:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OriginalFoundation Model Perplexity: 1901.6922739434885\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Trainer for the Foundation Model\n",
    "foundation_trainer = Trainer(\n",
    "    model=foundation_model,\n",
    "    args=training_args,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Evaluate the Orifinal Foundation Model\n",
    "eval_results_foundation = foundation_trainer.evaluate()\n",
    "perplexity_foundation = math.exp(eval_results_foundation['eval_loss'])\n",
    "print(f\"OriginalFoundation Model Perplexity: {perplexity_foundation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e753029-0ed1-43b1-abc0-334aa1ad9995",
   "metadata": {},
   "source": [
    "## Compute BLEU Score for Foundation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e849780a-89b5-4f69-a46b-36edfb2b8338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orifinal Foundation Model SacreBLEU Score: 1.502236402963001e-12\n"
     ]
    }
   ],
   "source": [
    "# Define the Response Generation Function for the Foundation Model\n",
    "# def generate_response_foundation(model, tokenizer, instruction):\n",
    "#     # Use eos_token for consistency with the model's pretraining\n",
    "#     conversation = (\n",
    "#         f\"<BOS> User: {instruction} </BOS>\"\n",
    "#         f\"<BOS> Assistant:\"\n",
    "#     )\n",
    "#     inputs = tokenizer(conversation, return_tensors='pt', padding=True).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model.generate(\n",
    "#             input_ids=inputs[\"input_ids\"],\n",
    "#             attention_mask=inputs[\"attention_mask\"],\n",
    "#             max_new_tokens=50,\n",
    "#             pad_token_id=tokenizer.pad_token_id,\n",
    "#             eos_token_id=tokenizer.eos_token_id,\n",
    "#             top_p=0.9,\n",
    "#             temperature=0.7,\n",
    "#             do_sample=True,\n",
    "#         )\n",
    "#     response = tokenizer.decode(outputs[0], skip_special_tokens=True) # Decode the generated output\n",
    "#     assistant_reply = response.split('<BOS> Assistant:')[-1].strip()\n",
    "#     return assistant_reply\n",
    "\n",
    "def generate_response_foundation(model, tokenizer, instruction):\n",
    "    conversation = (\n",
    "        f\"{tokenizer.eos_token}User: {instruction}{tokenizer.eos_token}\"\n",
    "        f\"Assistant:\"\n",
    "    )\n",
    "    inputs = tokenizer(conversation, return_tensors='pt', padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_new_tokens=50,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            top_p=0.9,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True) # Decode the generated output\n",
    "    \n",
    "    assistant_reply = response.split(\"Assistant:\")[-1].strip()\n",
    "    return assistant_reply\n",
    "\n",
    "\n",
    "def compute_bleu_sacrebleu_foundation(model, tokenizer, dataset):\n",
    "    references = []\n",
    "    predictions = []\n",
    "    for example in dataset:\n",
    "        input_ids = example['input_ids']\n",
    "        labels = example['labels']\n",
    "        \n",
    "        conversation_text = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "        instruction_text = conversation_text.split('User:')[-1].split('Assistant:')[0].strip()\n",
    "        label_text = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "        reference_response = label_text.split('Assistant:')[-1].strip()        \n",
    "        generated_response = generate_response_foundation(model, tokenizer, instruction_text)\n",
    "\n",
    "        references.append(reference_response)\n",
    "        predictions.append(generated_response)\n",
    "    \n",
    "    bleu = BLEU()\n",
    "    score = bleu.corpus_score(predictions, [references])\n",
    "    return score.score\n",
    "\n",
    "bleu_score_foundation = compute_bleu_sacrebleu_foundation(foundation_model, tokenizer, eval_dataset)\n",
    "print(f\"Orifinal Foundation Model SacreBLEU Score: {bleu_score_foundation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef7be9-55d0-47e3-8a1e-52974c3d8cd3",
   "metadata": {},
   "source": [
    "## Compare the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bf267515-d397-456d-bc48-f1ad619e1876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Models:\n",
      "PEFT Model Perplexity: 3.845786708271636\n",
      "OriginalFoundation Model Perplexity: 1901.6922739434885\n",
      "PEFT Model SacreBLEU Score: 3.9768704821496477\n",
      "Original Foundation Model SacreBLEU Score: 1.502236402963001e-12\n"
     ]
    }
   ],
   "source": [
    "# Compare the Results\n",
    "print(\"\\nComparison of Models:\")\n",
    "print(f\"PEFT Model Perplexity: {perplexity_peft}\")\n",
    "print(f\"OriginalFoundation Model Perplexity: {perplexity_foundation}\")\n",
    "print(f\"PEFT Model SacreBLEU Score: {bleu_score_peft}\")\n",
    "print(f\"Original Foundation Model SacreBLEU Score: {bleu_score_foundation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f757a2-80f7-40c7-82ad-fb25a3cf94f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a03ac0c4-2b86-4011-93a1-34183611feba",
   "metadata": {},
   "source": [
    "# Save the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c0c5421e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./customer_support_chatbot_peft_model3/tokenizer_config.json',\n",
       " './customer_support_chatbot_peft_model3/special_tokens_map.json',\n",
       " './customer_support_chatbot_peft_model3/vocab.json',\n",
       " './customer_support_chatbot_peft_model3/merges.txt',\n",
       " './customer_support_chatbot_peft_model3/added_tokens.json',\n",
       " './customer_support_chatbot_peft_model3/tokenizer.json')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model.save_pretrained('./customer_support_chatbot_peft_model3')\n",
    "tokenizer.save_pretrained('./customer_support_chatbot_peft_model3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c94c865-7a76-447f-b42d-22fa37d06cee",
   "metadata": {},
   "source": [
    "# Plot Training and Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "04a60d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_training_history(trainer, output_path='training_and_validation_loss_plot.png'):\n",
    "    metrics = trainer.state.log_history\n",
    "    train_steps = []\n",
    "    train_loss = []\n",
    "    eval_steps = []\n",
    "    eval_loss = []\n",
    "\n",
    "    for entry in metrics:\n",
    "        if 'loss' in entry and 'learning_rate' in entry:\n",
    "            train_steps.append(entry['step'])\n",
    "            train_loss.append(entry['loss'])\n",
    "        elif 'eval_loss' in entry:\n",
    "            eval_steps.append(entry['step'])\n",
    "            eval_loss.append(entry['eval_loss'])\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot Training Loss\n",
    "    if train_steps and train_loss:\n",
    "        plt.plot(train_steps, train_loss, label='Training Loss', color='blue')\n",
    "\n",
    "    # Plot Validation Loss\n",
    "    if eval_steps and eval_loss:\n",
    "        plt.plot(eval_steps, eval_loss, label='Validation Loss', color='red')\n",
    "\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(output_path)\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(trainer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a56b1c",
   "metadata": {},
   "source": [
    "# Run with Saved Model\n",
    "Inference and Testing with PEFT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fc8e937c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2LMHeadModel(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 1024)\n",
       "        (wpe): Embedding(1024, 1024)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-23): 24 x GPT2Block(\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2SdpaAttention(\n",
       "              (c_attn): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=3072, nx=1024)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=1024, nx=1024)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=1024, nx=4096)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./customer_support_chatbot_peft_model3')\n",
    "peft_model = AutoPeftModelForCausalLM.from_pretrained('./customer_support_chatbot_peft_model3')\n",
    "\n",
    "# Set the pad_token to eos_token\n",
    "# Ensure pad_token is set\n",
    "if tokenizer.pad_token is None:\n",
    "    print(\"Padding token\")\n",
    "    # tokenizer.add_special_tokens({'pad_token': '[PAD]'}) # For fine-tuning the model on tasks requiring distinct padding\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "peft_model.to(device)\n",
    "peft_model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cee2bb4-4e3c-4788-9bab-3acdc7a79a7a",
   "metadata": {},
   "source": [
    "# Test the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "004e804e-55aa-4e35-904b-4a587feb1c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Responses Using the PEFT Model:\n",
      "--\n",
      "User: Can you help me to order more of this product I bought previously, order number 123?\n",
      "--\n",
      "Assistant: I'm sorry to hear that you are having trouble with ordering your product. I'm here to assist you in finding the appropriate information to assist you in purchasing your product. Could you please provide me with the order number or any other relevant details? This\n",
      "\n",
      "--\n",
      "User: How can I track my order which my order number is #1234\n",
      "--\n",
      "Assistant: I understand your confusion and I'm here to assist you with tracking your order number. To track your order, you can log into your account on our website and navigate to the \"Tracking\" section. You should be able to find your order number\n",
      "\n",
      "--\n",
      "User: I forgot my password, how can I reset it?\n",
      "--\n",
      "Assistant: I've got it figured out. You can reset your password in our secure system by logging in to our website and clicking on the Reset Password button on the top right corner of the page. Once you've done that, you'll be prompted to enter\n",
      "\n",
      "--\n",
      "User: How to return my product?\n",
      "--\n",
      "Assistant: I'm on your side! I'm here to assist you in returning your product. To retrieve your product, please follow these steps:\n",
      "1. Log in to your account.\n",
      "2. Navigate to the 'My Account' or 'Profile\n",
      "\n",
      "===============================================\n",
      "Responses from the Orifinal Foundation Model:\n",
      "--\n",
      "User: Can you help me to order more of this product I bought previously, order number 123?\n",
      "--\n",
      "Assistant: I can't find that number\n",
      "\n",
      "--\n",
      "User: How can I track my order which my order number is #1234\n",
      "--\n",
      "Assistant: how can I track my order which my order number is\n",
      "\n",
      "--\n",
      "User: I forgot my password, how can I reset it?\n",
      "--\n",
      "Assistant: Please be careful, I might have a few things to do...\n",
      "\n",
      "--\n",
      "User: How to return my product?\n",
      "--\n",
      "Assistant: What's your return policy?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_instructions = [\n",
    "    \"Can you help me to order more of this product I bought previously, order number 123?\",\n",
    "    \"How can I track my order which my order number is #1234\",\n",
    "    \"I forgot my password, how can I reset it?\",\n",
    "    \"How to return my product?\",\n",
    "]\n",
    "\n",
    "print(\"===============================================\")\n",
    "print(\"Responses Using the PEFT Model:\")\n",
    "for instruction in test_instructions:\n",
    "    response = generate_response_peft(peft_model, tokenizer, instruction)\n",
    "    print(f\"--\\nUser: {instruction}\")\n",
    "    print(f\"--\\nAssistant: {response}\\n\")\n",
    "\n",
    "print(\"===============================================\")\n",
    "print(\"Responses from the Orifinal Foundation Model:\")\n",
    "for instruction in test_instructions:\n",
    "    response = generate_response_foundation(foundation_model, tokenizer, instruction)\n",
    "    print(f\"--\\nUser: {instruction}\")\n",
    "    print(f\"--\\nAssistant: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd1378e-ba4b-4c2e-aadb-c0ead6405717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df9890-0143-45ac-8433-88e0db62c141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0f1f696-be8f-4ddf-b015-9c46e39a8aa4",
   "metadata": {},
   "source": [
    "# Interactive Widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "73023f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072cf41b9b684f7980c8ea29ac9d98c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Intent:', options=('unknown', 'create_account', 'registration_problems', 'review', 'plac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab4c006210649b8b7e3d2bc12c274cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Category:', options=('unknown', 'PAYMENT', 'REFUND', 'INVOICE', 'ACCOUNT', 'SUBSCRIPTION…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f90a5de00f49ebbd53573f17b8981b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Instruction:', placeholder='Enter your instruction here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc17ba31c47740b483a2cc5840869772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4615e55d5cf34cebb0feb734619b8272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Define options for intent and category\n",
    "intent_options = [\n",
    "    'unknown', 'create_account', 'registration_problems', 'review', 'place_order', 'set_up_shipping_address', \n",
    "    'track_order', 'change_order', 'recover_password', 'delivery_options', 'check_refund_policy', \n",
    "    'change_shipping_address', 'cancel_order', 'get_invoice', 'contact_customer_service', \n",
    "    'check_invoice', 'newsletter_subscription', 'switch_account', 'track_refund', 'delivery_period', \n",
    "    'check_cancellation_fee', 'edit_account', 'delete_account', 'get_refund', 'payment_issue', \n",
    "    'contact_human_agent', 'check_payment_methods', 'complaint'\n",
    "]\n",
    "\n",
    "category_options = [\n",
    "    'unknown', 'PAYMENT', 'REFUND', 'INVOICE', 'ACCOUNT', 'SUBSCRIPTION', 'ORDER', \n",
    "    'DELIVERY', 'SHIPPING', 'CANCEL', 'CONTACT', 'FEEDBACK'\n",
    "]\n",
    "\n",
    "# Create dropdown widgets for intent and category\n",
    "intent_dropdown = widgets.Dropdown(\n",
    "    options=intent_options,\n",
    "    description='Intent:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "category_dropdown = widgets.Dropdown(\n",
    "    options=category_options,\n",
    "    description='Category:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Create a text box for user instruction\n",
    "instruction_text = widgets.Text(\n",
    "    description='Instruction:',\n",
    "    placeholder='Enter your instruction here',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Create an output widget to display the response\n",
    "output = widgets.Output()\n",
    "\n",
    "# Define the function to generate the response\n",
    "def on_submit_clicked(b):\n",
    "    # Clear previous output\n",
    "    output.clear_output()\n",
    "    \n",
    "    # Retrieve the selected category, intent, and instruction text\n",
    "    category = category_dropdown.value\n",
    "    intent = intent_dropdown.value\n",
    "    instruction = instruction_text.value\n",
    "    \n",
    "    # Generate the response\n",
    "    response = generate_response_peft(peft_model, tokenizer, instruction, category=category, intent=intent)\n",
    "    \n",
    "    # Display the response\n",
    "    with output:\n",
    "        print(f\"User: {instruction}\")\n",
    "        print(f\"Assistant: {response}\\n\")\n",
    "\n",
    "# Create a submit button\n",
    "submit_button = widgets.Button(\n",
    "    description=\"Submit\",\n",
    "    button_style=\"primary\"\n",
    ")\n",
    "submit_button.on_click(on_submit_clicked)\n",
    "\n",
    "# Display the widgets and output\n",
    "display(intent_dropdown, category_dropdown, instruction_text, submit_button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c43edf2-ed92-4d83-97dd-4a006c60c407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74ed0c2-6a61-417c-a274-5533c27e5499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d89f2-706b-4770-bf60-fd0ef01c2c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a149d2-410b-4e30-8b3f-fd163aa82435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207be3c6-1747-4bb2-b7b8-05ce0b5e702a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59019fa0-f1f5-4cfa-9412-89fd73c2074b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906828d6-0490-4146-aae7-b41e0b20c849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f698a98-5e00-46d1-9ff0-94c974ec17a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a018ebef-cb48-46d5-9282-65e2ff455852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:genAI] *",
   "language": "python",
   "name": "conda-env-genAI-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
